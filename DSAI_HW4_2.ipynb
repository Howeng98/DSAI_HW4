{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSAI_HW4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThtQmcswiCDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d624fd45-401c-4ca6-9d75-0aca5eea6686"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 15 12:44:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCRRTBA8qcFl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7DYLZ3EiKOZ"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, Activation\n",
        "from keras.optimizers import Adam, SGD\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statistics import mean\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm \n",
        "from keras.utils import np_utils\n",
        "import xgboost as xgb\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vt1PrUlXxrZ"
      },
      "source": [
        "main_path = 'drive/MyDrive/Colab Notebooks/dsai_hw4/dataset'\n",
        "\n",
        "ordersDf = pd.read_csv(os.path.join(main_path, 'orders.csv'))  \n",
        "priorDf = pd.read_csv(os.path.join(main_path, 'order_products__prior.csv')) \n",
        "trainDf = pd.read_csv(os.path.join(main_path, 'order_products__train.csv')) \n",
        "productDf = pd.read_csv(os.path.join(main_path, 'products.csv')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iU8pY-gTJfG"
      },
      "source": [
        "rows, cols = (1000,50000)\n",
        "x_train = [[0]*cols]*rows\n",
        "for i in range(rows):\n",
        "  order_id = trainDf['order_id'][i]  \n",
        "  for j in range(100):\n",
        "    if trainDf['order_id'][j] == order_id:\n",
        "      product_id = trainDf['product_id'][j]\n",
        "      x_train[i][product_id] = 1      \n",
        "      \n",
        "x_train = np.array(x_train)\n",
        "print(x_train.shape)\n",
        "####################################################\n",
        "\n",
        "y_train  = [[0]*cols]*rows\n",
        "for i in range(rows):\n",
        "  order_id = trainDf['order_id'][i]\n",
        "  for j in range(100):\n",
        "    if trainDf['order_id'][j] == order_id:\n",
        "      if trainDf['reordered'][j] == 1:\n",
        "        product_id = trainDf['product_id'][j]\n",
        "        y_train[i][product_id] = 1\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "print(y_train.shape)\n",
        "####################################################\n",
        "\n",
        "previous_order_of_test = []\n",
        "order_of_test = []\n",
        "\n",
        "# get all the previous orders of test_orders, and keep in previous_order_of_test list\n",
        "for i in range(ordersDf['order_id'].count()):\n",
        "  if ordersDf['eval_set'][i] == 'test':\n",
        "    previous_order_id = ordersDf['order_id'][i-1]\n",
        "    test_order_id = ordersDf['order_id'][i]\n",
        "    previous_order_of_test.append(previous_order_id)\n",
        "    order_of_test.append(test_order_id)\n",
        "\n",
        "previous_order_of_test = np.array(previous_order_of_test)\n",
        "order_of_test = np.array(order_of_test)\n",
        "print(previous_order_of_test.shape)\n",
        "print(order_of_test.shape)\n",
        "####################################################\n",
        "\n",
        "# x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "# print(x_train.shape)\n",
        "# print(y_train.shape)\n",
        "# print(x_validate.shape)\n",
        "# print(y_validate.shape)\n",
        "\n",
        "# x_train = x_train[np.newaxis,:,:]\n",
        "# y_train = y_train[np.newaxis,:,:]\n",
        "# x_validate = x_validate[np.newaxis,:,:]\n",
        "# y_validate = y_validate[np.newaxis,:,:]\n",
        "# print(x_train.shape)\n",
        "# print(y_train.shape)\n",
        "# print(x_validate.shape)\n",
        "# print(y_validate.shape)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhF1nAC9uFbN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhAmZsHV74n7"
      },
      "source": [
        "x_test = [[0]*cols]*rows\n",
        "\n",
        "for index in tqdm(range(0, rows)):  \n",
        "  order_id = previous_order_of_test[index]\n",
        "  target_orders = priorDf[priorDf['order_id']==order_id]\n",
        "  # print(target_orders)\n",
        "  for j in range(target_orders['order_id'].count()):\n",
        "    x_test[index][target_orders.iat[j-1, 1]] = 1\n",
        "  \n",
        "x_test = np.array(x_test)\n",
        "print(x_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxz2VJHZi2n5"
      },
      "source": [
        "def build_model(shape):\n",
        "  model = Sequential()\n",
        "  # model.add(LSTM(units=20, input_shape=(shape[1],shape[2]), return_sequences=True, activation='tanh'))\n",
        "  # model.add(Dropout(0.2))\n",
        "  # model.add(LSTM(20, activation='tanh'))\n",
        "  # model.add(Dropout(0.2))  \n",
        "  # model.add(Dense(50000))   \n",
        "  # model.summary()\n",
        "\n",
        "  model.add(LSTM(20, input_shape=(shape[1], shape[2]), return_sequences=True))  \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Activation(\"sigmoid\"))\n",
        "  \n",
        "  model.add(LSTM(20, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  # model.add(Activation(\"sigmoid\"))\n",
        "  # model.add(LSTM(20, return_sequences=True))\n",
        "  # model.add(Dense(50000))\n",
        "  model.add(Dense(50000, activation='sigmoid'))\n",
        "  model.summary()\n",
        "  return model    \n",
        "\n",
        "# Build model\n",
        "model = build_model(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_XOEB_Aip0y"
      },
      "source": [
        "# Variables\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "lr = 0.001"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "RSYSdB0spWmb",
        "outputId": "973bff0d-5b08-4ffa-811b-99ccfb210814"
      },
      "source": [
        "parameters = {'eval_metric':'logloss', \n",
        "              'max_depth':'5', \n",
        "              'colsample_bytree':'0.5',    # 0.4\n",
        "              'subsample':'0.75',\n",
        "              'gpu_id':'0',\n",
        "              'tree_method':'gpu_hist'\n",
        "             }\n",
        "# X_train, y_train = x_train.drop('reordered', axis=1), x_train.reordered.astype(np.int)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "XGB = xgb.XGBClassifier(objective='binary:logistic', parameters=parameters, num_boost_round=10)\n",
        "model = XGB.fit(x_train, y_train)\n",
        "xgb.plot_importance(model)\n",
        "\n",
        "model.get_xgb_params()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 50000)\n",
            "(1000, 50000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9c50a302ea0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mXGB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary:logistic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0mxgb_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"eval_metric\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape (1000, 50000)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsbstjzmjJr5"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_validate.shape)\n",
        "print(y_validate.shape)\n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "# sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=1.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_validate, y_validate),shuffle=False, callbacks=[reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtr22ujWuDX7"
      },
      "source": [
        "\n",
        "# Plotting\n",
        "fig = plt.figure()\n",
        "plt.plot()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.savefig('model_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.savefig('model_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_JkAirO0U-Y"
      },
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# print(x_train.shape)\n",
        "# x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
        "# print(x_train.shape)\n",
        "# # y_train = y_train[0]\n",
        "# y_train = y_train.reshape(y_train.shape[0], y_train.shape[1]*y_train.shape[2])\n",
        "# # x_validate  = x_validate[0]\n",
        "# # y_validate  = y_validate[0]\n",
        "# rfc = RandomForestClassifier()\n",
        "# rfc.fit(x_train, y_train)\n",
        "# # print('The accuracy of RFC:', rfc.score(x_validate,y_validate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml6btWhf6h4L"
      },
      "source": [
        "# x_test = x_test[np.newaxis,:,:]\n",
        "print(x_test.shape)\n",
        "x_test = x_test[np.newaxis,:,:]\n",
        "result = model.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL46iMUp8qsQ"
      },
      "source": [
        "print(result.shape)\n",
        "count = 0\n",
        "# print(result[0][:100])\n",
        "\n",
        "for i in range(1000):\n",
        "  for j in range(50000):\n",
        "    if result[0][i][j] > 0.519:\n",
        "      count = count + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcwInOV6rSgz"
      },
      "source": [
        "print(count)\n",
        "# print(result[0][0][329])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7Bc7Frs9v_p"
      },
      "source": [
        "user_orders = [0]*80\n",
        "print(ordersDf[ordersDf[\"eval_set\"]==\"train\"].count())\n",
        "\n",
        "for index in range(trainDf['order_id'].count()):\n",
        "  if trainDf.iat[index, 0] != trainDf.iat[index-1, 0]:\n",
        "    # print(trainDf.iat[index-1, 2])\n",
        "    user_orders[trainDf.iat[index-1, 2]-1] = user_orders[trainDf.iat[index-1, 2]-1] +1\n",
        "\n",
        "print(user_orders)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKMvjPY69ov0"
      },
      "source": [
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "x = [0]*80\n",
        "\n",
        "for index in range(1, 80):\n",
        "  x[index-1] = index\n",
        "\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(x,user_orders)\n",
        "ax.set_ylabel('times',fontsize= 12)\n",
        "ax.set_xlabel('# of product',fontsize= 12)\n",
        "ax.set_title('all # of product purchased in trainning orders')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}